{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats analysis with Convolutional Neural Network\n",
    "\n",
    "#### The Dogs/Cats set is separated into a training set and a test set. The training set is used here to build the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first define the image properties (size and RGB color channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 120\n",
    "img_width = 120\n",
    "img_size = (img_height, img_width)\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the data directories and separate them based on dogs and cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_df(train_dir, img_height=img_height, img_width=img_width):\n",
    "    labels = []\n",
    "    for img_path in train_dir:\n",
    "        if img_path.split('.')[0] == 'cat':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    img_df = pd.DataFrame({'files' : train_dir,\n",
    "                           'label' : labels})\n",
    "    return img_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep only the 1000 cat and dog images to make training faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_df_trunc(train_dir, img_height=img_height, img_width=img_width):\n",
    "    labels = []\n",
    "    train_dir_trunc = []\n",
    "    cat_count = 0\n",
    "    dog_count = 0\n",
    "    for img_path in train_dir:\n",
    "        if img_path.split('.')[0] == 'cat':\n",
    "            if cat_count == 1000:\n",
    "                continue\n",
    "            else:\n",
    "                train_dir_trunc.append(img_path)\n",
    "                labels.append(0)\n",
    "                cat_count += 1\n",
    "        elif img_path.split('.')[0] == 'dog':\n",
    "            if dog_count == 1000:\n",
    "                continue\n",
    "            else:\n",
    "                train_dir_trunc.append(img_path)\n",
    "                labels.append(1)\n",
    "                dog_count += 1\n",
    "        elif dog_count == 1000 and cat_count == 1000:\n",
    "            break\n",
    "    img_df = pd.DataFrame({'files' : train_dir_trunc,\n",
    "                           'label' : labels})\n",
    "    return img_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tried both methods and measured accuracy. ```create_img_df``` is more accurate, but takes far longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              files  label\n",
      "0         cat.0.jpg      0\n",
      "1         cat.1.jpg      0\n",
      "2        cat.10.jpg      0\n",
      "3       cat.100.jpg      0\n",
      "4      cat.1000.jpg      0\n",
      "...             ...    ...\n",
      "1995  dog.10893.jpg      1\n",
      "1996  dog.10894.jpg      1\n",
      "1997  dog.10895.jpg      1\n",
      "1998  dog.10896.jpg      1\n",
      "1999  dog.10897.jpg      1\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.listdir('./train')\n",
    "img_df = create_img_df_trunc(train_dir)\n",
    "print(img_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we construct the CNN model and compile it. It consists of 3 convolutional layers that extract features from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have 2 classes each image can be, cat or dog\n",
    "num_classes = 2\n",
    "droupout = 0.35\n",
    "\n",
    "cat_dog_model = Sequential()\n",
    "\n",
    "cat_dog_model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_width, img_height, channels)))\n",
    "cat_dog_model.add(BatchNormalization())\n",
    "cat_dog_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cat_dog_model.add(Dropout(droupout))\n",
    "\n",
    "cat_dog_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cat_dog_model.add(BatchNormalization())\n",
    "cat_dog_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cat_dog_model.add(Dropout(droupout))\n",
    "\n",
    "cat_dog_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "cat_dog_model.add(BatchNormalization())\n",
    "cat_dog_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cat_dog_model.add(Dropout(droupout))\n",
    "\n",
    "cat_dog_model.add(Flatten())\n",
    "cat_dog_model.add(Dense(256, activation='relu'))\n",
    "cat_dog_model.add(BatchNormalization())\n",
    "cat_dog_model.add(Dropout(droupout))\n",
    "cat_dog_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "cat_dog_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up callbacks, i.e., conditions on the model to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5) #stop after 5 epochs if the loss value has not decreased.\n",
    "LR_reduction = ReduceLROnPlateau( #reduce the learning rate if the accuracy does not increase\n",
    "    monitor='val_accuracy',\n",
    "    patience=2, #start doing this on the second epoch\n",
    "    factor=0.5,\n",
    "    min_lr=1e-4\n",
    ")\n",
    "callbacks = [early_stopping, LR_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data frame into training and validation data and prepare data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 validated image filenames belonging to 2 classes.\n",
      "Found 400 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_df['label'] = img_df['label'].replace({0:'cat', 1:'dog'})\n",
    "\n",
    "train_df, valid_df = train_test_split(img_df, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=42,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_data_generator.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory='./train',\n",
    "    x_col='files', y_col='label',\n",
    "    target_size=img_size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "valid_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = valid_data_generator.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    directory='./train',\n",
    "    x_col='files', y_col='label',\n",
    "    target_size=img_size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_valid = valid_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "50/50 [==============================] - 33s 666ms/step - loss: 1.1178 - accuracy: 0.5681 - val_loss: 4.1706 - val_accuracy: 0.5026 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "50/50 [==============================] - 41s 824ms/step - loss: 0.7754 - accuracy: 0.5969 - val_loss: 7.8097 - val_accuracy: 0.5026 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.7454 - accuracy: 0.6006 - val_loss: 6.0328 - val_accuracy: 0.5052 - lr: 0.0010\n",
      "Epoch 4/8\n",
      "50/50 [==============================] - 44s 884ms/step - loss: 0.7117 - accuracy: 0.6144 - val_loss: 2.2780 - val_accuracy: 0.5130 - lr: 0.0010\n",
      "Epoch 5/8\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.7346 - accuracy: 0.6075 - val_loss: 1.2086 - val_accuracy: 0.5443 - lr: 0.0010\n",
      "Epoch 6/8\n",
      "50/50 [==============================] - 44s 883ms/step - loss: 0.6682 - accuracy: 0.6431 - val_loss: 1.4801 - val_accuracy: 0.5104 - lr: 0.0010\n",
      "Epoch 7/8\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.6420 - accuracy: 0.6469 - val_loss: 1.2743 - val_accuracy: 0.5521 - lr: 0.0010\n",
      "Epoch 8/8\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 0.6226 - accuracy: 0.6687 - val_loss: 2.2392 - val_accuracy: 0.5078 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "hist = cat_dog_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    epochs=8,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_valid//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog_model.save_weights('cat_dog_model_8epoch_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.listdir('./test1')\n",
    "test_df = pd.DataFrame({\n",
    "    'files':test_dir\n",
    "})\n",
    "num_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_data_generator.flow_from_dataframe(\n",
    "    test_df,\n",
    "    directory='./test1',\n",
    "    x_col='files', y_col=None,\n",
    "    target_size=img_size,\n",
    "    class_mode=None,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make further predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = cat_dog_model.predict(test_generator, steps=np.ceil(num_samples/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label'] = np.argmax(predict, axis=-1)\n",
    "submission = test_df.copy()\n",
    "submission['id'] = submission['files'].str.split('.').str[0]\n",
    "ids = submission['id']\n",
    "submission = submission.drop(['files', 'id'], axis=1)\n",
    "submission.insert(0, 'id', ids)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
